{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T14:54:44.020160Z",
     "start_time": "2019-10-31T14:54:12.942902Z"
    },
    "id": "YntzVlz7OsTW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Visual C++ Redistributable is not installed, this may lead to the DLL load failure.\n",
      "                 It can be downloaded at https://aka.ms/vs/16/release/vc_redist.x64.exe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T14:56:33.343538Z",
     "start_time": "2019-10-31T14:56:33.340405Z"
    },
    "id": "UZCIjAKDOsTs"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T14:56:33.884461Z",
     "start_time": "2019-10-31T14:56:33.880453Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "-pzuNZbYOsTt",
    "outputId": "c9457f97-1d42-400c-9491-645ded9ce87f"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "#         self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(input_dim, enc_hid_dim, n_layers, bidirectional = True)\n",
    "        self.linear = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hid_dim=enc_hid_dim\n",
    "        self.n_layers=n_layers\n",
    "        \n",
    "    def forward(self, src):\n",
    "#         embedded = self.embedding(src)\n",
    "#         embedded = self.dropout(embedded)     \n",
    "#         print(embedded.shape)\n",
    "        outputs, hidden = self.rnn(src)\n",
    "#         print('enc hidden={}'.format(hidden.shape))\n",
    "        concat_hiddens = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        concat_hiddens = self.linear(concat_hiddens)\n",
    "        concat_hiddens = torch.tanh(concat_hiddens)\n",
    "        return outputs, concat_hiddens\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        # print(hidden.shape)\n",
    "        hidden = hidden.unsqueeze(1)\n",
    "        # print(hidden.shape)\n",
    "        hidden = hidden.repeat(1, src_len, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        energy = energy.permute(0, 2, 1)\n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
    "        attention = torch.bmm(v, energy).squeeze(1)\n",
    "        attention = self.softmax(attention)\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X,D,count_of_delays_elements,batch_size=10):\n",
    "    for j in range(0,X.shape[0],batch_size):\n",
    "        yield torch.cat(([X[i-count_of_delays_elements:i+1,:,:] if i > count_of_delays_elements else \\\n",
    "        torch.cat((torch.zeros(count_of_delays_elements-i,1,2),X[:i+1,:,:]),dim=0) \n",
    "            for i in range(j,batch_size+j)]),dim=1),\\\n",
    "        torch.cat(([D[i-count_of_delays_elements:i+1,:,:] if i > count_of_delays_elements else \\\n",
    "        torch.cat((torch.zeros(count_of_delays_elements-i,1,2),D[:i+1,:,:]),dim=0) \n",
    "            for i in range(j,batch_size+j)]),dim=1)\n",
    "#         D[:,i:i+1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Data/BlackBoxData_80'\n",
    "# name = 'BlackBoxData'\n",
    "# name = '../BlackBoxData/data1'\n",
    "mat = scipy.io.loadmat(name)\n",
    "x = np.array(mat['x']).reshape(-1,1)/2**15\n",
    "d = np.array(mat['y']).reshape(-1,1)/2**15\n",
    "# x = np.array(mat['xE']).reshape(-1,1)/2**15\n",
    "# d = np.array(mat['d']).reshape(-1,1)/2**15\n",
    "# x, d = mat['xE'], mat['d']\n",
    "x_real, x_imag = torch.from_numpy(np.real(x)), torch.from_numpy(np.imag(x))\n",
    "d_real, d_imag = torch.from_numpy(np.real(d)), torch.from_numpy(np.imag(d))\n",
    "X = torch.DoubleTensor(torch.cat((x_real, x_imag))).reshape(2,-1,1).type(torch.FloatTensor).permute(1,2,0)\n",
    "D = torch.DoubleTensor(torch.cat((d_real, d_imag))).reshape(2,-1,1).type(torch.FloatTensor).permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        batch_size = src.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs = torch.zeros_like( trg).to(self.device)\n",
    " \n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "#         print('seq2seq enc_outputs={} hidden={}'.format(encoder_outputs.shape,hidden.shape))\n",
    "                \n",
    "        input = trg[0]\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "#             print('seq2seq_input={}'.format(input.shape))\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "#             print(output.shape)\n",
    "            outputs[t,:,:] = output\n",
    "            \n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            top1 = output\n",
    "#             print('seq2seq_top1={}'.format(top1))\n",
    "\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eyoMjFP15f_P"
   },
   "outputs": [],
   "source": [
    "# import my_network\n",
    "# Encoder = Encoder\n",
    "# Decoder = Decoder\n",
    "# Seq2Seq = Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim,n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.attention = Attention(enc_hid_dim, dec_hid_dim).to(device)\n",
    "#         self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU((enc_hid_dim)+output_dim + emb_dim, dec_hid_dim,n_layers)\n",
    "        self.out = nn.Linear((enc_hid_dim*2) + output_dim + dec_hid_dim , output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hid_dim=enc_hid_dim\n",
    "        self.n_layers=n_layers\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "#         print('inp={}'.format(input))\n",
    "#         embedded = self.embedding(input)\n",
    "#         embedded = self.dropout(embedded)\n",
    "        \n",
    "        att = self.attention(hidden, encoder_outputs)\n",
    "#         print('hid={},enc_outputs={},input={},att={}'.format(hidden.shape,encoder_outputs.shape,input.shape,att.shape))\n",
    "\n",
    "        att = att.unsqueeze(1)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)        \n",
    "        weighted = torch.bmm(att, encoder_outputs)\n",
    "#         print('dec enc_out={}, weighted={}, att={}'.format(encoder_outputs.shape,weighted.shape,att.shape))\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "#         print('weight={}'.format(torch.unique(weighted)))\n",
    "        rnn_input = torch.cat((input, weighted), dim = 2)        \n",
    "#         print('dec weighted={}, rnn_inp={}'.format(weighted.shape,rnn_input.shape))\n",
    "\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "#         print(torch.unique(rnn_input))\n",
    "#         print(torch.unique(weighted))\n",
    "#         print('kjnfrkjernfkjen')\n",
    "#         embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        input = input.squeeze(0)\n",
    "#         print('dec weighted={}, output={}'.format(weighted.shape,output.shape))\n",
    "\n",
    "#         print('out_shape={}'.format(torch.cat((output, weighted, input), dim = 1).shape))\n",
    "        output = self.out(torch.cat((output, weighted, input), dim = 1))\n",
    "#         print('dec_out={}'.format(output))\n",
    "        \n",
    "        return output, hidden.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ENqY11O49TzK"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 2\n",
    "OUTPUT_DIM = 2\n",
    "ENC_EMB_DIM = 2\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, HID_DIM,1, DEC_DROPOUT)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "train_dataloader=batch_generator(X,D,10,6)\n",
    "# src,v=train_dataloader.__next__()\n",
    "# model(src, v, teacher_forcing_ratio = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "kU5bvtCmL45T",
    "outputId": "a38e9f74-ca22-4007-a4dd-7ef8072e6a2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(2, 256, num_layers=2, bidirectional=True)\n",
       "    (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=768, out_features=256, bias=True)\n",
       "      (softmax): Softmax(dim=1)\n",
       "    )\n",
       "    (rnn): GRU(514, 256)\n",
       "    (out): Linear(in_features=770, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    # <YOUR CODE HERE>\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.008, 0.008)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T14:59:08.809322Z",
     "start_time": "2019-10-31T14:59:08.796614Z"
    },
    "id": "HiNrq8srOsT1"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    output_sig=[]\n",
    "    output_sig_for_acc=torch.zeros((1,2))\n",
    "    i=1\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch[0]\n",
    "        trg = batch[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        output_sig=np.hstack((output_sig,\n",
    "                              np.apply_along_axis(lambda args: [complex(*args)],\n",
    "                                                  1, (output[-1,:,:].data)).reshape(-1)))\n",
    "        output_sig_for_acc=torch.cat((output_sig_for_acc,output[-1,:,:]))\n",
    "        output = output.view(-1)\n",
    "#         print(output.shape)\n",
    "        trg = trg.view(-1)\n",
    "#         print(trg.shape)\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        history.append(loss.item())\n",
    "#         print('i={}'.format(i))\n",
    "\n",
    "    return epoch_loss / i, output_sig, output_sig_for_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T14:59:11.786655Z",
     "start_time": "2019-10-31T14:59:11.782902Z"
    },
    "id": "Q6gb-YupOsT3"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T14:59:14.294060Z",
     "start_time": "2019-10-31T14:59:14.290775Z"
    },
    "id": "M4ziiBNPOsT4"
   },
   "outputs": [],
   "source": [
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "# best_valid_loss = float('inf')\n",
    "\n",
    "# PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2,4,6,8,10,12], gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMSE(X, E):\n",
    "    return 10 * torch.log10((torch.pow((E).norm(dim=2), 2)).sum() / (torch.pow((X).norm(dim=2), 2)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T15:06:03.941939Z",
     "start_time": "2019-10-31T14:59:17.526887Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "KDP9ro3cOsT5",
    "outputId": "5cc18fc1-86f3-452e-db4d-d01718df842f"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (99840) must match the size of tensor b (99841) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-b1b4187d1471>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mepoch_mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_secs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0msignal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (99840) must match the size of tensor b (99841) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "accuracy=[]\n",
    "train_dataloader=batch_generator(X,D,10,6)\n",
    "best_valid_loss=0\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss , signal_for_drawing,signal= train(model, train_dataloader, optimizer, loss_fn, CLIP, train_history, valid_history)\n",
    "#     valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    scheduler.step()\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    signal=signal.unsqueeze(1)\n",
    "    accuracy.append(NMSE(X,D-signal).item())\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "    \n",
    "    clear_output(True)\n",
    "    ax[0].plot(accuracy, label='train NMSE')\n",
    "    ax[0].set_xlabel('Batch')\n",
    "    ax[0].set_title('Train loss')\n",
    "    ax[1].psd(x.reshape(-1),NFFT=2048,label='X')\n",
    "    ax[1].psd(d.reshape(-1),NFFT=2048,label='D')\n",
    "#     outputs=torch.complex(outputs[0,:,:],outputs[1,:,:]).detach().cpu().view(-1)\n",
    "    ax[1].psd(no,NFFT=2048,label='output')\n",
    "    ax[1].psd(d.reshape(-1)-no,NFFT=2048,label='eOut')\n",
    "    ax[1].legend()\n",
    "    ax[1].grid()\n",
    "    # Draw figure on canvas\n",
    "#     fig.canvas.draw()\n",
    "#     if train_history is not None:\n",
    "#         ax[1].plot(train_history, label='general train history')\n",
    "#         ax[1].set_xlabel('Epoch')\n",
    "#     if valid_history is not None:\n",
    "#         ax[1].plot(valid_history, label='general valid history')\n",
    "#     plt.legend()\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "    if accuracy[-1] < best_valid_loss:\n",
    "        best_valid_loss = accuracy[-1] \n",
    "        torch.save(model.state_dict(), './experiment_data/att_dpd/tut1-model.pt')\n",
    "    \n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {accuracy[-1]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99841, 1, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99840,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-16.2566, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMSE(X,D-signal[1:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3qRpzJJOsT6"
   },
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "28FWZIxalfOs",
    "outputId": "c6b95a32-db23-4d9b-c14e-271cced20087"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T15:06:05.964474Z",
     "start_time": "2019-10-31T15:06:05.958506Z"
    },
    "id": "ZjewiUXPOsT7"
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import imp\n",
    "imp.reload(utils)\n",
    "generate_translation = utils.generate_translation\n",
    "remove_tech_tokens = utils.remove_tech_tokens\n",
    "get_text = utils.get_text\n",
    "flatten = utils.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T15:06:06.787935Z",
     "start_time": "2019-10-31T15:06:06.775206Z"
    },
    "id": "ukGFCiIsOsT8"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T15:06:08.743845Z",
     "start_time": "2019-10-31T15:06:08.657935Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "kSdIJR4BOsT8",
    "outputId": "94c7dd3c-de8b-447a-a37c-751918e4311c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the property offers free parking .\n",
      "Generated: wichita free parking is available on site . parking is provided .\n",
      "\n",
      "Original: you will find a kettle in the room .\n",
      "Generated: wichita you will find a kettle in the room . room . kettle . kettle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in [1,2]:\n",
    "    src = batch.src[:, idx:idx+1]\n",
    "    trg = batch.trg[:, idx:idx+1]\n",
    "    generate_translation(src, trg, model, TRG.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T15:06:15.304382Z",
     "start_time": "2019-10-31T15:06:15.301696Z"
    },
    "id": "2spLiYKoOsT9"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T15:06:16.936284Z",
     "start_time": "2019-10-31T15:06:16.933711Z"
    },
    "id": "jKFDn-8EOsT-"
   },
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T15:06:54.111825Z",
     "start_time": "2019-10-31T15:06:20.616549Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Kgch5U4POsT_",
    "outputId": "5133e3da-9fb7-4802-d867-01c4650494d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:07,  3.69it/s]\n"
     ]
    }
   ],
   "source": [
    "original_text = []\n",
    "generated_text = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "        output = output.argmax(dim=-1)\n",
    "        \n",
    "        original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n",
    "        generated_text.extend([get_text(x, TRG.vocab) for x in output.detach().cpu().numpy().T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T15:06:55.072474Z",
     "start_time": "2019-10-31T15:06:54.202786Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "bnR_C0N_OsUA",
    "outputId": "fd3b5362-1d49-469e-b1bf-ee31895e16a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.092799185499636\n"
     ]
    }
   ],
   "source": [
    "corpus_bleu([[text] for text in original_text], generated_text) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUPqpBkNOsUB"
   },
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __18__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __18__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __20__ - good score, 70% of points\n",
    "\n",
    "* __25__ - excellent score, 100% of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oold version\n",
    "def batch_generator(X,D,count_of_delays_elements,batch_size=10):\n",
    "    for j in range(0,X.shape[1],10):\n",
    "        yield X[:,i-count_of_delays_elements:i+1,:]if i > count_of_delays_elements else \\\n",
    "        torch.cat((torch.zeros(1,count_of_delays_elements-i,2),X[:,:i+1,:]),dim=1),\\\n",
    "        D[:,i-count_of_delays_elements:i+1,:]if i > count_of_delays_elements else \\\n",
    "        torch.cat((torch.zeros(1,count_of_delays_elements-i,2),D[:,:i+1,:]),dim=1)\n",
    "#         D[:,i:i+1,:]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Lab1_NLP_part_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
